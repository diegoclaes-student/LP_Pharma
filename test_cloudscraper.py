#!/usr/bin/env python3
"""
Test rapide pour v√©rifier si cloudscraper contourne Cloudflare sur NewPharma.
"""

import cloudscraper
import time
from bs4 import BeautifulSoup
import json

print("="*70)
print("üß™ TEST CLOUDSCRAPER - NewPharma Cloudflare Bypass")
print("="*70)

# Cr√©er le scraper cloudscraper
print("\n1Ô∏è‚É£  Cr√©ation du scraper cloudscraper...")
scraper = cloudscraper.create_scraper(
    browser={
        'browser': 'chrome',
        'platform': 'windows',
        'mobile': False
    }
)
print("   ‚úÖ Scraper cr√©√©")

# Test 1: Page d'accueil
print("\n2Ô∏è‚É£  Test page d'accueil NewPharma...")
try:
    resp = scraper.get('https://www.newpharma.be/pharmacie/', timeout=30)
    print(f"   Status: {resp.status_code}")
    
    if resp.status_code == 200:
        print("   ‚úÖ Acc√®s r√©ussi!")
        # V√©rifier si on a le vrai contenu ou une page Cloudflare
        if 'Attention Required' in resp.text or 'Cloudflare' in resp.text[:1000]:
            print("   ‚ùå Page Cloudflare Challenge d√©tect√©e")
        else:
            print("   ‚úÖ Contenu r√©el obtenu (pas de Cloudflare)")
    elif resp.status_code == 403:
        print("   ‚ùå BLOQU√â (403) - cloudscraper n'a pas suffi")
    else:
        print(f"   ‚ö†Ô∏è  Status inattendu: {resp.status_code}")
except Exception as e:
    print(f"   ‚ùå Erreur: {e}")

# Test 2: Recherche produit
print("\n3Ô∏è‚É£  Test recherche produit (Dafalgan)...")
time.sleep(2)  # Petit d√©lai entre les requ√™tes

try:
    url = 'https://www.newpharma.be/fr/search-results/search.html?q=dafalgan'
    resp = scraper.get(url, timeout=30)
    print(f"   Status: {resp.status_code}")
    
    if resp.status_code == 200:
        print("   ‚úÖ Recherche r√©ussie!")
        
        # Parser et chercher les produits
        soup = BeautifulSoup(resp.content, "lxml")
        divs = soup.find_all("div", attrs={"data-google-360": True})
        
        print(f"   üìä {len(divs)} div(s) avec data-google-360 trouv√©s")
        
        if divs:
            print("\n   üéØ Produits trouv√©s:")
            for i, div in enumerate(divs[:3]):  # Afficher les 3 premiers
                raw = div.get("data-google-360", "")
                try:
                    data = json.loads(raw.replace("&quot;", '"'))
                    items = data.get("ecommerce", {}).get("items", [])
                    
                    for item in items:
                        name = item.get("item_name", "")
                        price = item.get("price", "")
                        if name and price:
                            print(f"      ‚Ä¢ {name[:60]}... ‚Üí {price}‚Ç¨")
                            break
                except:
                    pass
            
            print("\n   ‚úÖ cloudscraper FONCTIONNE! NewPharma accessible!")
        else:
            print("   ‚ö†Ô∏è  Aucun produit trouv√© (structure HTML diff√©rente?)")
            
    elif resp.status_code == 403:
        print("   ‚ùå BLOQU√â (403) - cloudscraper insuffisant")
        print("   ‚Üí Solution: VPS Belgique ou Playwright requis")
    else:
        print(f"   ‚ö†Ô∏è  Status inattendu: {resp.status_code}")
        
except Exception as e:
    print(f"   ‚ùå Erreur: {e}")

print("\n" + "="*70)
print("üìä CONCLUSION")
print("="*70)
print("Si vous voyez '‚úÖ cloudscraper FONCTIONNE', vous pouvez:")
print("  1. Lancer un test complet avec --limit 10")
print("  2. Scraper NewPharma sans probl√®me!")
print("\nSi vous voyez '‚ùå BLOQU√â', il faudra:")
print("  1. Essayer un VPS en Belgique (5‚Ç¨/mois)")
print("  2. Ou utiliser Playwright + cloudscraper")
print("="*70)
